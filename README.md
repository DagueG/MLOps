# Credit Scoring MLOps Project

Projet de scoring crÃ©dit avec une approche MLOps complÃ¨te, du tracking des expÃ©riences Ã  la prÃ©-production du modÃ¨le.

## Objectif

Construire un modÃ¨le de classification automatisÃ© pour prÃ©dire la probabilitÃ© qu'un client rembourse son crÃ©dit, avec :
- âœ“ Optimisation des hyperparamÃ¨tres
- âœ“ Gestion du dÃ©sÃ©quilibre de classe
- âœ“ Optimisation du seuil mÃ©tier (minimisation du coÃ»t FN/FP)
- âœ“ Transparency (SHAP, Feature Importance)
- âœ“ MLOps (MLflow, Model Registry, Serving)

---

## Architecture du Projet

```
MLOps/
â”œâ”€â”€ notebooks/              # Notebooks Jupyter pour chaque Ã©tape
â”‚   â”œâ”€â”€ 01_data_preparation.ipynb
â”‚   â”œâ”€â”€ 02_model_training.ipynb
â”‚   â”œâ”€â”€ 03_hyperparameter_optimization.ipynb
â”‚   â””â”€â”€ 04_feature_importance_threshold.ipynb
â”œâ”€â”€ src/                    # Code rÃ©utilisable
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ models.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ models/                 # ModÃ¨les sauvegardÃ©s
â”œâ”€â”€ outputs/                # DonnÃ©es gÃ©nÃ©rÃ©es
â”‚   â”œâ”€â”€ train_processed.csv
â”‚   â””â”€â”€ test_processed.csv
â”œâ”€â”€ logs/                   # Logs MLflow
â”œâ”€â”€ datasets/               # DonnÃ©es brutes
â”œâ”€â”€ pyproject.toml          # Configuration uv
â””â”€â”€ README.md              # Ce fichier
```

---

## Ã‰tapes du Projet

### âœ… Ã‰tape 1 - PrÃ©paration des DonnÃ©es
**Status:** ComplÃ©tÃ©e

- Chargement et fusion de 8 sources de donnÃ©es
- Gestion des valeurs manquantes (imputation mÃ©diane/mode)
- Encodage des variables catÃ©gorielles
- Analyse du dÃ©sÃ©quilibre de classe (91.9% / 8.1%)

**RÃ©sultats:**
- Dataset d'entraÃ®nement: 307,511 Ã— 148 colonnes
- Dataset de test: 48,744 Ã— 121 colonnes
- ZÃ©ro valeurs manquantes

---

### âœ… Ã‰tape 2 - MLflow Tracking & EntraÃ®nement des ModÃ¨les
**Status:** ComplÃ©tÃ©e

- EntraÃ®nement de 4 modÃ¨les baseline: Logistic Regression, Random Forest, XGBoost, LightGBM
- Validation croisÃ©e stratifiÃ©e (5-fold StratifiedKFold)
- Logging automatique avec MLflow
- Ã‰valuation sur mÃ©triques techniques et mÃ©tier (coÃ»t FN=10x, FP=1x)

**RÃ©sultats:**
| ModÃ¨le | AUC | Accuracy | Business Cost | CV AUC |
|--------|-----|----------|---------------|--------|
| LightGBM | 0.7657 | 0.7132 | 159,859 | 0.7657 |
| XGBoost | 0.7655 | 0.7153 | 159,658 | 0.7655 |
| Logistic Reg. | 0.7573 | 0.6950 | 163,281 | 0.7573 |
| Random Forest | 0.7413 | 0.7382 | 169,766 | 0.7413 |

---

### â³ Ã‰tape 3 - Optimisation des HyperparamÃ¨tres
**Status:** En cours

- GridSearchCV sur LightGBM et XGBoost
- Recherche d'hyperparamÃ¨tres optimaux (n_estimators, max_depth, learning_rate)
- Logging des essais avec MLflow
- Comparaison baseline vs optimized

---

### â³ Ã‰tape 4 - Feature Importance & Optimisation du Seuil
**Status:** En cours

- Optimisation du seuil de dÃ©cision basÃ© sur coÃ»t mÃ©tier
- Feature Importance par permutation
- Feature Importance globale avec SHAP (TreeExplainer)
- Sauvegarder le modÃ¨le final avec seuil optimal dans Model Registry

---

## Installation

### PrÃ©requis
- Python >= 3.10
- uv (gestionnaire de paquets)

### Setup

```bash
# Installer les dÃ©pendances
uv sync

# Lancer un notebook
uv run jupyter notebook notebooks/01_data_preparation.ipynb

# Lancer MLflow (aprÃ¨s Ã‰tape 2)
uv run mlflow ui
```

---

## DonnÃ©es

Les donnÃ©es proviennent du challenge Kaggle "Home Credit Default Risk".

**Tables principales:**
- `application_train.csv` - DonnÃ©es d'entraÃ®nement (307k clients)
- `application_test.csv` - DonnÃ©es de test (48k clients)
- `bureau.csv` - Historique crÃ©dit bureau
- `bureau_balance.csv` - Soldes mensuels bureau
- `credit_card_balance.csv` - Soldes cartes de crÃ©dit
- `installments_payments.csv` - Historique des versements
- `POS_CASH_balance.csv` - Soldes point de vente
- `previous_application.csv` - Applications antÃ©rieures

---

## Points ClÃ©s

âš ï¸ **DÃ©sÃ©quilibre de classe:** 91.9% bons clients vs 8.1% mauvais
â†’ Ã€ gÃ©rer avec `class_weight='balanced'` ou SMOTE

ğŸ“Š **CoÃ»t mÃ©tier:** FN (mauvais client acceptÃ©) coÃ»te 10x plus que FP (bon client refusÃ©)
â†’ Optimiser le seuil selon ce ratio

ğŸ¯ **Benchmark:** Kaggle winner AUC = 0.82
â†’ Attention Ã  l'overfitting si AUC > 0.82

---

## Auteur

Data Scientist - OpenClassrooms Project

---

## Statut du Projet

ğŸŸ¡ En cours - Ã‰tape 1 complÃ©tÃ©e
