# Credit Scoring MLOps Project

Projet de scoring crÃ©dit avec une approche MLOps complÃ¨te, du tracking des expÃ©riences Ã  la prÃ©-production du modÃ¨le.

## Objectif

Construire un modÃ¨le de classification automatisÃ© pour prÃ©dire la probabilitÃ© qu'un client rembourse son crÃ©dit, avec :
- âœ“ Optimisation des hyperparamÃ¨tres
- âœ“ Gestion du dÃ©sÃ©quilibre de classe
- âœ“ Optimisation du seuil mÃ©tier (minimisation du coÃ»t FN/FP)
- âœ“ Transparency (SHAP, Feature Importance)
- âœ“ MLOps (MLflow, Model Registry, Serving)

---

## Architecture du Projet

```
MLOps/
â”œâ”€â”€ notebooks/              # Notebooks Jupyter pour chaque Ã©tape
â”‚   â”œâ”€â”€ 01_data_preparation.ipynb
â”‚   â”œâ”€â”€ 02_eda_and_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 03_model_training.ipynb
â”‚   â””â”€â”€ 04_model_optimization.ipynb
â”œâ”€â”€ src/                    # Code rÃ©utilisable
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ models.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ models/                 # ModÃ¨les sauvegardÃ©s
â”œâ”€â”€ outputs/                # DonnÃ©es gÃ©nÃ©rÃ©es
â”‚   â”œâ”€â”€ train_processed.csv
â”‚   â””â”€â”€ test_processed.csv
â”œâ”€â”€ logs/                   # Logs MLflow
â”œâ”€â”€ datasets/               # DonnÃ©es brutes
â”œâ”€â”€ pyproject.toml          # Configuration uv
â””â”€â”€ README.md              # Ce fichier
```

---

## Ã‰tapes du Projet

### âœ… Ã‰tape 1 - PrÃ©paration des DonnÃ©es
**Status:** ComplÃ©tÃ©e

- Chargement et fusion de 8 sources de donnÃ©es
- Gestion des valeurs manquantes (imputation mÃ©diane/mode)
- Encodage des variables catÃ©gorielles
- Analyse du dÃ©sÃ©quilibre de classe (91.9% / 8.1%)

**RÃ©sultats:**
- Dataset d'entraÃ®nement: 307,511 Ã— 148 colonnes
- Dataset de test: 48,744 Ã— 121 colonnes
- ZÃ©ro valeurs manquantes

---

### â³ Ã‰tape 2 - MLflow Tracking & Exploration
**Status:** Ã€ faire

- Mise en place du tracking MLflow
- Lancement de l'interface web MLflow
- Configuration du Model Registry

---

### â³ Ã‰tape 3 - EntraÃ®nement & Comparaison des ModÃ¨les
**Status:** Ã€ faire

- EntraÃ®nement de plusieurs modÃ¨les (Logistic Regression, Random Forest, XGBoost, LightGBM)
- Validation croisÃ©e stratifiÃ©e
- Ã‰valuation sur des mÃ©triques mÃ©tier (coÃ»t FN/FP) et techniques (AUC, Accuracy)

---

### â³ Ã‰tape 4 - Optimisation & Feature Importance
**Status:** Ã€ faire

- Optimisation des hyperparamÃ¨tres (GridSearchCV/Optuna)
- Optimisation du seuil de dÃ©cision
- Feature Importance globale (SHAP) et locale
- SÃ©lection du meilleur modÃ¨le

---

## Installation

### PrÃ©requis
- Python >= 3.10
- uv (gestionnaire de paquets)

### Setup

```bash
# Installer les dÃ©pendances
uv sync

# Lancer un notebook
uv run jupyter notebook notebooks/01_data_preparation.ipynb

# Lancer MLflow (aprÃ¨s Ã‰tape 2)
uv run mlflow ui
```

---

## DonnÃ©es

Les donnÃ©es proviennent du challenge Kaggle "Home Credit Default Risk".

**Tables principales:**
- `application_train.csv` - DonnÃ©es d'entraÃ®nement (307k clients)
- `application_test.csv` - DonnÃ©es de test (48k clients)
- `bureau.csv` - Historique crÃ©dit bureau
- `bureau_balance.csv` - Soldes mensuels bureau
- `credit_card_balance.csv` - Soldes cartes de crÃ©dit
- `installments_payments.csv` - Historique des versements
- `POS_CASH_balance.csv` - Soldes point de vente
- `previous_application.csv` - Applications antÃ©rieures

---

## Points ClÃ©s

âš ï¸ **DÃ©sÃ©quilibre de classe:** 91.9% bons clients vs 8.1% mauvais
â†’ Ã€ gÃ©rer avec `class_weight='balanced'` ou SMOTE

ğŸ“Š **CoÃ»t mÃ©tier:** FN (mauvais client acceptÃ©) coÃ»te 10x plus que FP (bon client refusÃ©)
â†’ Optimiser le seuil selon ce ratio

ğŸ¯ **Benchmark:** Kaggle winner AUC = 0.82
â†’ Attention Ã  l'overfitting si AUC > 0.82

---

## Auteur

Data Scientist - OpenClassrooms Project

---

## Statut du Projet

ğŸŸ¡ En cours - Ã‰tape 1 complÃ©tÃ©e
