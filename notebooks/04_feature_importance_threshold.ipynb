{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a5d60f5",
   "metadata": {},
   "source": [
    "# Etape 4 - Feature Importance & Optimisation du Seuil\n",
    "\n",
    "Objectif: Analyser l'importance des features avec SHAP et optimiser le seuil de d√©cision bas√© sur le co√ªt m√©tier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d765cb2",
   "metadata": {},
   "source": [
    "## 1. Import et configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c6fae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root: C:\\Users\\daniel.guedj_arondor\\Downloads\\perso\\openclassrooms\\MLOps\n",
      "Data: C:\\Users\\daniel.guedj_arondor\\Downloads\\perso\\openclassrooms\\MLOps\\outputs\n",
      "Models: C:\\Users\\daniel.guedj_arondor\\Downloads\\perso\\openclassrooms\\MLOps\\models\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.inspection import permutation_importance\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Paths\n",
    "ROOT_DIR = Path('.').resolve().parent\n",
    "DATA_DIR = ROOT_DIR / 'outputs'\n",
    "MODELS_DIR = ROOT_DIR / 'models'\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Root: {ROOT_DIR}\")\n",
    "print(f\"Data: {DATA_DIR}\")\n",
    "print(f\"Models: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045552d5",
   "metadata": {},
   "source": [
    "## 2. Charger les donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1568234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des donnees...\n",
      "Train shape: (307511, 148)\n",
      "Test shape: (48744, 121)\n"
     ]
    }
   ],
   "source": [
    "print(\"Chargement des donnees...\")\n",
    "train = pd.read_csv(DATA_DIR / 'train_processed.csv')\n",
    "test = pd.read_csv(DATA_DIR / 'test_processed.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51763ccf",
   "metadata": {},
   "source": [
    "## 3. Pr√©parer les donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b48824ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (307511, 146)\n",
      "y_train shape: (307511,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop('TARGET', axis=1)\n",
    "y_train = train['TARGET']\n",
    "\n",
    "if 'TARGET' in test.columns:\n",
    "    X_test = test.drop('TARGET', axis=1)\n",
    "    y_test = test['TARGET']\n",
    "else:\n",
    "    X_test = test.copy()\n",
    "    y_test = None\n",
    "\n",
    "if 'SK_ID_CURR' in X_test.columns:\n",
    "    test_ids = X_test['SK_ID_CURR'].copy()\n",
    "    X_train = X_train.drop('SK_ID_CURR', axis=1, errors='ignore')\n",
    "    X_test = X_test.drop('SK_ID_CURR', axis=1)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170fad79",
   "metadata": {},
   "source": [
    "## 4. Configuration MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce518bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: credit_scoring_v1\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri('http://localhost:5000')\n",
    "experiment_name = 'credit_scoring_v1'\n",
    "\n",
    "try:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "except:\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "print(f\"Experiment: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82af4c",
   "metadata": {},
   "source": [
    "## 5. Charger le meilleur mod√®le optimis√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bfd40d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LightGBM run: 0e8fbdf54a8d45fc9083e0ec9579d281\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d70e28721b84c41b15adb267d925534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a36d23d914f476ead27334144ee3c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod√®le charg√©: <class 'lightgbm.sklearn.LGBMClassifier'>\n"
     ]
    }
   ],
   "source": [
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "all_runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "lgb_optimized = all_runs[all_runs['tags.mlflow.runName'] == 'lightgbm_gridsearch']\n",
    "\n",
    "if len(lgb_optimized) > 0:\n",
    "    best_run_id = lgb_optimized.iloc[0]['run_id']\n",
    "    print(f\"Best LightGBM run: {best_run_id}\")\n",
    "    \n",
    "    model_uri = f\"runs:/{best_run_id}/model\"\n",
    "    best_model = mlflow.sklearn.load_model(model_uri)\n",
    "    print(f\"Mod√®le charg√©: {type(best_model)}\")\n",
    "else:\n",
    "    print(\"Aucun mod√®le LightGBM optimis√© trouv√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aba8ce",
   "metadata": {},
   "source": [
    "## 6. Fonction de m√©triques avec seuil personnalis√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c8d83c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonction avec seuil personnalis√©: OK\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics_with_threshold(y_true, y_proba, threshold, cost_fn=10, cost_fp=1):\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "    metrics['precision'] = precision_score(y_true, y_pred, zero_division=0)\n",
    "    metrics['recall'] = recall_score(y_true, y_pred, zero_division=0)\n",
    "    metrics['f1'] = f1_score(y_true, y_pred, zero_division=0)\n",
    "    metrics['auc'] = roc_auc_score(y_true, y_proba) if len(np.unique(y_true)) > 1 else 0\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    metrics['business_cost'] = fn * cost_fn + fp * cost_fp\n",
    "    metrics['tn'] = int(tn)\n",
    "    metrics['fp'] = int(fp)\n",
    "    metrics['fn'] = int(fn)\n",
    "    metrics['tp'] = int(tp)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"Fonction avec seuil personnalis√©: OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a06f3b",
   "metadata": {},
   "source": [
    "## 7. Optimisation du seuil de d√©cision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "050f0028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OPTIMISATION DU SEUIL ===\n",
      "\n",
      "Seuil optimal (co√ªt minimal): 0.50\n",
      "Co√ªt m√©tier minimal: 157859‚Ç¨\n",
      "\n",
      "Top 5 thresholds par co√ªt:\n",
      " threshold  accuracy  precision   recall       f1  business_cost\n",
      "      0.50  0.722989   0.178459 0.674723 0.282262         157859\n",
      "      0.55  0.768763   0.197200 0.607090 0.297699         158894\n",
      "      0.45  0.670743   0.161881 0.736959 0.265453         160020\n",
      "      0.60  0.809834   0.220355 0.534099 0.311991         162572\n",
      "      0.40  0.610967   0.146556 0.791782 0.247332         166153\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== OPTIMISATION DU SEUIL ===\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_proba_cv = cross_val_predict(best_model, X_train, y_train, cv=skf, method='predict_proba')[:, 1]\n",
    "\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    metrics = calculate_metrics_with_threshold(y_train, y_proba_cv, threshold)\n",
    "    results.append({\n",
    "        'threshold': threshold,\n",
    "        'accuracy': metrics['accuracy'],\n",
    "        'precision': metrics['precision'],\n",
    "        'recall': metrics['recall'],\n",
    "        'f1': metrics['f1'],\n",
    "        'business_cost': metrics['business_cost']\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "best_threshold = results_df.loc[results_df['business_cost'].idxmin(), 'threshold']\n",
    "min_cost = results_df['business_cost'].min()\n",
    "\n",
    "print(f\"\\nSeuil optimal (co√ªt minimal): {best_threshold:.2f}\")\n",
    "print(f\"Co√ªt m√©tier minimal: {min_cost:.0f}‚Ç¨\")\n",
    "print(f\"\\nTop 5 thresholds par co√ªt:\")\n",
    "print(results_df.nsmallest(5, 'business_cost').to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8047254e",
   "metadata": {},
   "source": [
    "## 8. Feature Importance - Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "872a93ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FEATURE IMPORTANCE - PERMUTATION ===\n",
      "Calcul de l'importance par permutation...\n",
      "\n",
      "Top 15 features par importance de permutation:\n",
      "               feature  importance      std\n",
      "             pos_count    0.019698 0.000233\n",
      "     installments_mean    0.012891 0.000160\n",
      "            DAYS_BIRTH    0.011678 0.000146\n",
      "pos_future_installment    0.011289 0.000219\n",
      "          payment_mean    0.009213 0.000228\n",
      "      installments_sum    0.008542 0.000146\n",
      "       AMT_GOODS_PRICE    0.006712 0.000308\n",
      "           CODE_GENDER    0.006560 0.000234\n",
      "    installments_count    0.006519 0.000138\n",
      "    previous_app_count    0.006100 0.000221\n",
      "          EXT_SOURCE_1    0.005417 0.000374\n",
      "          EXT_SOURCE_2    0.004530 0.000226\n",
      " credit_card_limit_sum    0.002761 0.000104\n",
      "         DAYS_EMPLOYED    0.002031 0.000252\n",
      "          EXT_SOURCE_3    0.002018 0.000450\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== FEATURE IMPORTANCE - PERMUTATION ===\")\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Calcul de l'importance par permutation...\")\n",
    "perm_importance = permutation_importance(\n",
    "    best_model, X_train, y_train, \n",
    "    n_repeats=10, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "perm_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': perm_importance.importances_mean,\n",
    "    'std': perm_importance.importances_std\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 15 features par importance de permutation:\")\n",
    "print(perm_df.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387084fb",
   "metadata": {},
   "source": [
    "## 9. Feature Importance - SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4676943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FEATURE IMPORTANCE - SHAP ===\n",
      "Calcul des valeurs SHAP (cela peut prendre quelques minutes)...\n",
      "Valeurs SHAP calcul√©es sur 5000 √©chantillons\n",
      "\n",
      "Top 15 features par SHAP importance:\n",
      "               feature  shap_importance\n",
      "          EXT_SOURCE_2         0.344688\n",
      "          EXT_SOURCE_3         0.306874\n",
      "          EXT_SOURCE_1         0.161831\n",
      "       AMT_GOODS_PRICE         0.132442\n",
      "           CODE_GENDER         0.125872\n",
      "            AMT_CREDIT         0.118006\n",
      "         DAYS_EMPLOYED         0.103186\n",
      "             pos_count         0.103061\n",
      "   NAME_EDUCATION_TYPE         0.100994\n",
      "pos_future_installment         0.094159\n",
      "           AMT_ANNUITY         0.090659\n",
      "            DAYS_BIRTH         0.089482\n",
      "          payment_mean         0.085007\n",
      "      bureau_debt_mean         0.079684\n",
      "           payment_sum         0.079625\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== FEATURE IMPORTANCE - SHAP ===\")\n",
    "\n",
    "print(\"Calcul des valeurs SHAP (cela peut prendre quelques minutes)...\")\n",
    "\n",
    "sample_size = min(5000, len(X_train))\n",
    "sample_indices = np.random.choice(len(X_train), sample_size, replace=False)\n",
    "X_sample = X_train.iloc[sample_indices]\n",
    "\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "print(f\"Valeurs SHAP calcul√©es sur {sample_size} √©chantillons\")\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "    shap_vals = shap_values[1]\n",
    "else:\n",
    "    shap_vals = shap_values\n",
    "\n",
    "feature_importance_shap = np.abs(shap_vals).mean(axis=0)\n",
    "shap_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'shap_importance': feature_importance_shap\n",
    "}).sort_values('shap_importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 15 features par SHAP importance:\")\n",
    "print(shap_df.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ac9e50",
   "metadata": {},
   "source": [
    "## 10. Sauvegarder le mod√®le final au Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa3779c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL REGISTRY ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/09 14:20:40 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/09 14:20:50 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod√®le final sauvegard√© avec seuil optimal: 0.50\n",
      "üèÉ View run final_model_with_threshold at: http://localhost:5000/#/experiments/1/runs/e3d6e8a07ba74c59bca07cf3e6c54bf0\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "print('\\n=== MODEL REGISTRY ===')\n",
    "\n",
    "with mlflow.start_run(run_name='final_model_with_threshold'):\n",
    "    mlflow.sklearn.log_model(best_model, 'model')\n",
    "    \n",
    "    mlflow.log_param('optimal_threshold', best_threshold)\n",
    "    mlflow.log_metric('min_business_cost', min_cost)\n",
    "    \n",
    "    perm_df.to_csv(MODELS_DIR / 'feature_importance_permutation.csv', index=False)\n",
    "    mlflow.log_artifact(str(MODELS_DIR / 'feature_importance_permutation.csv'))\n",
    "    \n",
    "    mlflow.set_tag('model_type', 'LightGBM')\n",
    "    mlflow.set_tag('threshold_optimized', 'True')\n",
    "    mlflow.set_tag('stage', 'production')\n",
    "    \n",
    "    print(f'Mod√®le final sauvegard√© avec seuil optimal: {best_threshold:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6aa296",
   "metadata": {},
   "source": [
    "## 11. R√©sum√© final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d609dd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== R√âSUM√â FINAL ===\n",
      "‚úÖ Meilleur mod√®le: LightGBM\n",
      "‚úÖ Seuil optimal: 0.50\n",
      "‚úÖ Co√ªt m√©tier minimal: 157859‚Ç¨\n",
      "‚úÖ Top 5 features (SHAP):\n",
      "        feature  shap_importance\n",
      "   EXT_SOURCE_2         0.344688\n",
      "   EXT_SOURCE_3         0.306874\n",
      "   EXT_SOURCE_1         0.161831\n",
      "AMT_GOODS_PRICE         0.132442\n",
      "    CODE_GENDER         0.125872\n",
      "\n",
      "‚úÖ Tous les runs logg√©s dans MLflow (experiment: credit_scoring_v1)\n",
      "‚úÖ Mod√®le pr√™t pour deployment\n"
     ]
    }
   ],
   "source": [
    "print('\\n=== R√âSUM√â FINAL ===')\n",
    "print(f'‚úÖ Meilleur mod√®le: LightGBM')\n",
    "print(f'‚úÖ Seuil optimal: {best_threshold:.2f}')\n",
    "print(f'‚úÖ Co√ªt m√©tier minimal: {min_cost:.0f}‚Ç¨')\n",
    "print(f'‚úÖ Top 5 features (SHAP):')\n",
    "print(shap_df.head(5).to_string(index=False))\n",
    "print(f'\\n‚úÖ Tous les runs logg√©s dans MLflow (experiment: {experiment_name})')\n",
    "print(f'‚úÖ Mod√®le pr√™t pour deployment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f216ee3",
   "metadata": {},
   "source": [
    "## Prochaines √©tapes\n",
    "\n",
    "- Batch scoring sur dataset de test\n",
    "- API REST pour predictions en temps r√©el\n",
    "- Monitoring et retraining"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "credit-scoring-mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
