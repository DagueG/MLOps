{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a5d60f5",
   "metadata": {},
   "source": [
    "# Etape 4 - Feature Importance & Optimisation du Seuil\n",
    "\n",
    "Objectif: Analyser l'importance des features avec SHAP et optimiser le seuil de d√©cision bas√© sur le co√ªt m√©tier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d765cb2",
   "metadata": {},
   "source": [
    "## 1. Import et configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c6fae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root: C:\\Users\\daniel.guedj_arondor\\Downloads\\perso\\openclassrooms\\MLOps\n",
      "Data: C:\\Users\\daniel.guedj_arondor\\Downloads\\perso\\openclassrooms\\MLOps\\outputs\n",
      "Models: C:\\Users\\daniel.guedj_arondor\\Downloads\\perso\\openclassrooms\\MLOps\\models\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.inspection import permutation_importance\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Paths\n",
    "ROOT_DIR = Path('.').resolve().parent\n",
    "DATA_DIR = ROOT_DIR / 'outputs'\n",
    "MODELS_DIR = ROOT_DIR / 'models'\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Root: {ROOT_DIR}\")\n",
    "print(f\"Data: {DATA_DIR}\")\n",
    "print(f\"Models: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045552d5",
   "metadata": {},
   "source": [
    "## 2. Charger les donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1568234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des donnees...\n",
      "Train shape: (307511, 158)\n",
      "Test shape: (48744, 131)\n"
     ]
    }
   ],
   "source": [
    "print(\"Chargement des donnees...\")\n",
    "\n",
    "train = pd.read_parquet(DATA_DIR / \"train_processed.parquet\")\n",
    "test = pd.read_parquet(DATA_DIR / \"test_processed.parquet\")\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51763ccf",
   "metadata": {},
   "source": [
    "## 3. Pr√©parer les donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b48824ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (307511, 156)\n",
      "y_train shape: (307511,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop('TARGET', axis=1)\n",
    "y_train = train['TARGET']\n",
    "\n",
    "if 'TARGET' in test.columns:\n",
    "    X_test = test.drop('TARGET', axis=1)\n",
    "    y_test = test['TARGET']\n",
    "else:\n",
    "    X_test = test.copy()\n",
    "    y_test = None\n",
    "\n",
    "if 'SK_ID_CURR' in X_test.columns:\n",
    "    test_ids = X_test['SK_ID_CURR'].copy()\n",
    "    X_train = X_train.drop('SK_ID_CURR', axis=1, errors='ignore')\n",
    "    X_test = X_test.drop('SK_ID_CURR', axis=1)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170fad79",
   "metadata": {},
   "source": [
    "## 4. Configuration MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce518bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: credit_scoring_v1\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri('http://localhost:5000')\n",
    "experiment_name = 'credit_scoring_v1'\n",
    "\n",
    "try:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "except:\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "print(f\"Experiment: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82af4c",
   "metadata": {},
   "source": [
    "## 5. Charger le meilleur mod√®le optimis√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bfd40d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LightGBM run: 7e387338cecd4f77b136c2e34aad7c61 (business_cost=157922.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e4c5cdbc1046b6b147aa11565ea3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc4d5a8beac493387db7fc9e4d5e53e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod√®le charg√©: <class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "all_runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "# Filtrer les runs LightGBM (baseline ou gridsearch)\n",
    "lgb_runs = all_runs[all_runs['tags.mlflow.runName'].str.contains('lightgbm', case=False, na=False)]\n",
    "\n",
    "if len(lgb_runs) > 0:\n",
    "    # S√©lectionner le run avec le co√ªt m√©tier minimal\n",
    "    best_idx = lgb_runs['metrics.business_cost'].astype(float).idxmin()\n",
    "    best_run = lgb_runs.loc[best_idx]\n",
    "    best_run_id = best_run['run_id']\n",
    "    print(f\"Best LightGBM run: {best_run_id} (business_cost={best_run['metrics.business_cost']})\")\n",
    "    \n",
    "    model_uri = f\"runs:/{best_run_id}/model\"\n",
    "    best_model = mlflow.sklearn.load_model(model_uri)\n",
    "    print(f\"Mod√®le charg√©: {type(best_model)}\")\n",
    "else:\n",
    "    print(\"Aucun mod√®le LightGBM trouv√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aba8ce",
   "metadata": {},
   "source": [
    "## 6. Fonction de m√©triques avec seuil personnalis√©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a06f3b",
   "metadata": {},
   "source": [
    "## 7. Optimisation du seuil de d√©cision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "050f0028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OPTIMISATION DU SEUIL ===\n",
      "\n",
      "Seuil optimal (co√ªt minimal): 0.51\n",
      "Co√ªt m√©tier minimal: 157764‚Ç¨\n",
      "\n",
      "Top 5 thresholds par co√ªt:\n",
      " threshold  accuracy  precision   recall       f1  business_cost     tn    fp   fn    tp\n",
      "      0.51  0.726985   0.179956 0.669648 0.283679         157764 206932 75754 8201 16624\n",
      "      0.50  0.715935   0.176007 0.684149 0.279985         157922 203174 79512 7841 16984\n",
      "      0.54  0.757576   0.192411 0.626465 0.294400         158005 217411 65275 9273 15552\n",
      "      0.52  0.737092   0.183563 0.654542 0.286718         158031 210415 72271 8576 16249\n",
      "      0.53  0.747333   0.187752 0.640322 0.290364         158059 213917 68769 8929 15896\n",
      "\n",
      "Confusion matrix (optimal, threshold=0.51):\n",
      "   TN=206932, FP=75754, FN=8201, TP=16624\n",
      "\n",
      "Confusion matrix (baseline, threshold=0.50):\n",
      "   TN=203174, FP=79512, FN=7841, TP=16984\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics_with_threshold(y_true, y_proba, threshold, cost_fn=10, cost_fp=1):\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"auc\": roc_auc_score(y_true, y_proba),\n",
    "        \"business_cost\": fn * cost_fn + fp * cost_fp,\n",
    "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)\n",
    "    }\n",
    "\n",
    "print(\"\\n=== OPTIMISATION DU SEUIL ===\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_proba_cv = cross_val_predict(best_model, X_train, y_train, cv=skf, method='predict_proba')[:, 1]\n",
    "\n",
    "# Grille fine de seuils\n",
    "thresholds = np.arange(0.01, 1.0, 0.01)\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    metrics = calculate_metrics_with_threshold(y_train, y_proba_cv, threshold)\n",
    "    results.append({\n",
    "        'threshold': threshold,\n",
    "        'accuracy': metrics['accuracy'],\n",
    "        'precision': metrics['precision'],\n",
    "        'recall': metrics['recall'],\n",
    "        'f1': metrics['f1'],\n",
    "        'business_cost': metrics['business_cost'],\n",
    "        'tn': metrics['tn'],\n",
    "        'fp': metrics['fp'],\n",
    "        'fn': metrics['fn'],\n",
    "        'tp': metrics['tp']\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "best_threshold = results_df.loc[results_df['business_cost'].idxmin(), 'threshold']\n",
    "min_cost = results_df['business_cost'].min()\n",
    "\n",
    "print(f\"\\nSeuil optimal (co√ªt minimal): {best_threshold:.2f}\")\n",
    "print(f\"Co√ªt m√©tier minimal: {min_cost:.0f}‚Ç¨\")\n",
    "print(f\"\\nTop 5 thresholds par co√ªt:\")\n",
    "print(results_df.nsmallest(5, 'business_cost').to_string(index=False))\n",
    "\n",
    "# Afficher la matrice de confusion pour le seuil optimal et le seuil baseline (0.5)\n",
    "for t, label in zip([best_threshold, 0.5], [\"optimal\", \"baseline\"]):\n",
    "    m = calculate_metrics_with_threshold(y_train, y_proba_cv, t)\n",
    "    print(f\"\\nConfusion matrix ({label}, threshold={t:.2f}):\")\n",
    "    print(f\"   TN={m['tn']}, FP={m['fp']}, FN={m['fn']}, TP={m['tp']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8047254e",
   "metadata": {},
   "source": [
    "## 8. Feature Importance - Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "872a93ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FEATURE IMPORTANCE - PERMUTATION ===\n",
      "Calcul de l'importance par permutation...\n",
      "\n",
      "Top 15 features par importance de permutation:\n",
      "                 feature  importance      std\n",
      "               pos_count    0.010714 0.000194\n",
      "         AMT_GOODS_PRICE    0.009259 0.000255\n",
      "             AMT_ANNUITY    0.007746 0.000217\n",
      "             CODE_GENDER    0.006308 0.000159\n",
      "       installments_mean    0.005080 0.000122\n",
      "  pos_future_installment    0.004771 0.000196\n",
      "            EXT_SOURCE_2    0.004582 0.000444\n",
      "            payment_mean    0.004124 0.000207\n",
      "              DAYS_BIRTH    0.003397 0.000177\n",
      "                     AGE    0.002890 0.000084\n",
      "      NAME_FAMILY_STATUS    0.002672 0.000205\n",
      "credit_card_balance_mean    0.002313 0.000257\n",
      "      installments_count    0.002157 0.000040\n",
      "            FLAG_OWN_CAR    0.001492 0.000195\n",
      "            EXT_SOURCE_3    0.001266 0.000325\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== FEATURE IMPORTANCE - PERMUTATION ===\")\n",
    "\n",
    "# S'assurer que le mod√®le est bien fit (cross_val_predict ne fit pas sur tout le train)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Calcul de l'importance par permutation...\")\n",
    "perm_importance = permutation_importance(\n",
    "    best_model, X_train, y_train, \n",
    "    n_repeats=10, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "perm_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': perm_importance.importances_mean,\n",
    "    'std': perm_importance.importances_std\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 15 features par importance de permutation:\")\n",
    "print(perm_df.head(15).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387084fb",
   "metadata": {},
   "source": [
    "## 9. Feature Importance - SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4676943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FEATURE IMPORTANCE - SHAP ===\n",
      "Calcul des valeurs SHAP (cela peut prendre quelques minutes)...\n",
      "Valeurs SHAP calcul√©es sur 5000 √©chantillons\n",
      "\n",
      "Top 15 features par SHAP importance:\n",
      " feature_idx  shap_importance\n",
      "          28         0.333897\n",
      "          29         0.313919\n",
      "          27         0.147785\n",
      "         108         0.120538\n",
      "           4         0.095093\n",
      "         166         0.077407\n",
      "           3         0.077078\n",
      "         143         0.072647\n",
      "         119         0.066924\n",
      "         123         0.061543\n",
      "         136         0.057713\n",
      "         134         0.056507\n",
      "         132         0.055499\n",
      "         171         0.052047\n",
      "         120         0.046757\n"
     ]
    }
   ],
   "source": [
    "# (Optionnel) FEATURE IMPORTANCE - SHAP\n",
    "try:\n",
    "    import shap\n",
    "    print(\"\\n=== FEATURE IMPORTANCE - SHAP ===\")\n",
    "    print(\"Calcul des valeurs SHAP (cela peut prendre quelques minutes)...\")\n",
    "    sample_size = min(5000, len(X_train))\n",
    "    sample_indices = np.random.choice(len(X_train), sample_size, replace=False)\n",
    "    X_sample = X_train.iloc[sample_indices]\n",
    "    if hasattr(best_model, 'named_steps') and 'preprocess' in best_model.named_steps and 'model' in best_model.named_steps:\n",
    "        pre = best_model.named_steps['preprocess']\n",
    "        lgb_model = best_model.named_steps['model']\n",
    "        X_trans = pre.transform(X_sample)\n",
    "        explainer = shap.TreeExplainer(lgb_model)\n",
    "        shap_values = explainer.shap_values(X_trans)\n",
    "    else:\n",
    "        explainer = shap.TreeExplainer(best_model)\n",
    "        shap_values = explainer.shap_values(X_sample)\n",
    "    print(f\"Valeurs SHAP calcul√©es sur {sample_size} √©chantillons\")\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_vals = shap_values[1]\n",
    "    else:\n",
    "        shap_vals = shap_values\n",
    "    feature_importance_shap = np.abs(shap_vals).mean(axis=0)\n",
    "    shap_df = pd.DataFrame({\n",
    "        'feature_idx': np.arange(len(feature_importance_shap)),\n",
    "        'shap_importance': feature_importance_shap\n",
    "    }).sort_values('shap_importance', ascending=False)\n",
    "    print(f\"\\nTop 15 features par SHAP importance:\")\n",
    "    print(shap_df.head(15).to_string(index=False))\n",
    "except ImportError:\n",
    "    print(\"SHAP n'est pas install√©. Importance SHAP non calcul√©e.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ac9e50",
   "metadata": {},
   "source": [
    "## 10. Sauvegarder le mod√®le final au Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa3779c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL RUN (MODEL + THRESHOLD + ARTIFACTS) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/19 16:40:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/19 16:40:39 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run lightgbm_final_threshold_optimized at: http://localhost:5000/#/experiments/1/runs/5968d7d15ff540b087d16b49a949980f\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "print('\\n=== FINAL RUN (MODEL + THRESHOLD + ARTIFACTS) ===')\n",
    "\n",
    "perm_path = MODELS_DIR / 'feature_importance_permutation.csv'\n",
    "perm_df.to_csv(perm_path, index=False)\n",
    "\n",
    "with mlflow.start_run(run_name=\"lightgbm_final_threshold_optimized\"):\n",
    "    mlflow.sklearn.log_model(best_model, \"model\")\n",
    "    mlflow.log_metric(\"min_business_cost\", float(min_cost))\n",
    "    mlflow.log_metric(\"optimal_threshold\", float(best_threshold))\n",
    "    mlflow.log_metric(\"cv_auc_oof\", float(roc_auc_score(y_train, y_proba_cv)))\n",
    "    mlflow.log_artifact(str(perm_path))\n",
    "\n",
    "    mlflow.set_tag(\"candidate\", \"final\")\n",
    "    mlflow.set_tag(\"threshold_optimized\", \"true\")\n",
    "    mlflow.set_tag(\"feature_importance\", \"permutation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6aa296",
   "metadata": {},
   "source": [
    "## 11. R√©sum√© final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d609dd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "R√âSUM√â: √âTAPE 4 - FEATURE IMPORTANCE & OPTIMISATION DU SEUIL\n",
      "======================================================================\n",
      "\n",
      "‚úÖ ANALYSES IMPL√âMENT√âES:\n",
      "\n",
      "1. OPTIMISATION DU SEUIL DE D√âCISION\n",
      "   ‚Ä¢ Seuils test√©s: de 0.01 √† 0.99 par pas de 0.01\n",
      "   ‚Ä¢ Optimisation bas√©e sur le co√ªt m√©tier\n",
      "   ‚Ä¢ Co√ªt m√©tier: FN*10 + FP*1\n",
      "   ‚Ä¢ Seuil optimal: 0.51\n",
      "   ‚Ä¢ Co√ªt minimal: 157764‚Ç¨\n",
      "\n",
      "2. FEATURE IMPORTANCE - PERMUTATION\n",
      "   ‚Ä¢ M√©thode: Diminution de l'importance suite √† permutation\n",
      "   ‚Ä¢ 10 r√©p√©titions pour stabilit√©\n",
      "   ‚Ä¢ Top 15 features extraites\n",
      "   ‚Ä¢ Fichier: models/feature_importance_permutation.csv\n",
      "\n",
      "3. FEATURE IMPORTANCE - SHAP (optionnel)\n",
      "   ‚Ä¢ M√©thode: TreeExplainer (optimis√©e pour LightGBM)\n",
      "   ‚Ä¢ Calcul sur 5,000 √©chantillons\n",
      "   ‚Ä¢ Interpr√©tabilit√© du mod√®le am√©lior√©e\n",
      "   ‚Ä¢ Top 15 features par importance SHAP\n",
      "\n",
      "4. MODEL REGISTRY\n",
      "   ‚Ä¢ Meilleur mod√®le LightGBM sauvegard√©\n",
      "   ‚Ä¢ Seuil optimal: 0.51\n",
      "   ‚Ä¢ Co√ªt minimal log√©: 157764‚Ç¨\n",
      "   ‚Ä¢ Tags: candidate=\"final\", threshold_optimized=\"true\"\n",
      "\n",
      "üìä M√âTRIQUES FINALES:\n",
      "   ‚Ä¢ Accuracy: 0.7270\n",
      "   ‚Ä¢ Precision: 0.1800\n",
      "   ‚Ä¢ Recall: 0.6696\n",
      "   ‚Ä¢ F1-Score: 0.2837\n",
      "   ‚Ä¢ Matrice confusion: TP=16624, TN=206932, FP=75754, FN=8201\n",
      "\n",
      "üéØ TOP 5 FEATURES PAR IMPORTANCE (PERMUTATION):\n",
      "          feature  importance      std\n",
      "        pos_count    0.010714 0.000194\n",
      "  AMT_GOODS_PRICE    0.009259 0.000255\n",
      "      AMT_ANNUITY    0.007746 0.000217\n",
      "      CODE_GENDER    0.006308 0.000159\n",
      "installments_mean    0.005080 0.000122\n",
      "\n",
      "üéØ TOP 5 FEATURES PAR IMPORTANCE (SHAP):\n",
      " feature_idx  shap_importance\n",
      "          28         0.333897\n",
      "          29         0.313919\n",
      "          27         0.147785\n",
      "         108         0.120538\n",
      "           4         0.095093\n",
      "\n",
      "======================================================================\n",
      "‚úÖ √âTAPE 4 COMPL√àT√âE - MOD√àLE FINAL PR√äT POUR DEPLOYMENT\n",
      "======================================================================\n",
      "\n",
      "üìÅ FICHIERS G√âN√âR√âS:\n",
      "   ‚Ä¢ models/feature_importance_permutation.csv\n",
      "   ‚Ä¢ MLFlow Experiment: credit_scoring_v1\n",
      "\n",
      "üöÄ NEXT STEPS - DEPLOYMENT:\n",
      "   1. Batch scoring sur test set\n",
      "   2. API REST pour pr√©dictions en temps r√©el\n",
      "   3. Monitoring et retraining p√©riodique\n",
      "   4. Model versioning dans MLFlow Model Registry\n"
     ]
    }
   ],
   "source": [
    "print('\\n' + '='*70)\n",
    "print('R√âSUM√â: √âTAPE 4 - FEATURE IMPORTANCE & OPTIMISATION DU SEUIL')\n",
    "print('='*70)\n",
    "\n",
    "print('\\n‚úÖ ANALYSES IMPL√âMENT√âES:')\n",
    "print(f'\\n1. OPTIMISATION DU SEUIL DE D√âCISION')\n",
    "print(f'   ‚Ä¢ Seuils test√©s: de 0.01 √† 0.99 par pas de 0.01')\n",
    "print(f'   ‚Ä¢ Optimisation bas√©e sur le co√ªt m√©tier')\n",
    "print(f'   ‚Ä¢ Co√ªt m√©tier: FN*10 + FP*1')\n",
    "print(f'   ‚Ä¢ Seuil optimal: {best_threshold:.2f}')\n",
    "print(f'   ‚Ä¢ Co√ªt minimal: {min_cost:.0f}‚Ç¨')\n",
    "\n",
    "print(f'\\n2. FEATURE IMPORTANCE - PERMUTATION')\n",
    "print(f'   ‚Ä¢ M√©thode: Diminution de l\\'importance suite √† permutation')\n",
    "print(f'   ‚Ä¢ 10 r√©p√©titions pour stabilit√©')\n",
    "print(f'   ‚Ä¢ Top 15 features extraites')\n",
    "print(f'   ‚Ä¢ Fichier: models/feature_importance_permutation.csv')\n",
    "\n",
    "print(f'\\n3. FEATURE IMPORTANCE - SHAP (optionnel)')\n",
    "print(f'   ‚Ä¢ M√©thode: TreeExplainer (optimis√©e pour LightGBM)')\n",
    "print(f'   ‚Ä¢ Calcul sur {min(5000, len(X_train)):,} √©chantillons')\n",
    "print(f'   ‚Ä¢ Interpr√©tabilit√© du mod√®le am√©lior√©e')\n",
    "print(f'   ‚Ä¢ Top 15 features par importance SHAP')\n",
    "\n",
    "print(f'\\n4. MODEL REGISTRY')\n",
    "print(f'   ‚Ä¢ Meilleur mod√®le LightGBM sauvegard√©')\n",
    "print(f'   ‚Ä¢ Seuil optimal: {best_threshold:.2f}')\n",
    "print(f'   ‚Ä¢ Co√ªt minimal log√©: {min_cost:.0f}‚Ç¨')\n",
    "print(f'   ‚Ä¢ Tags: candidate=\"final\", threshold_optimized=\"true\"')\n",
    "\n",
    "print('\\nüìä M√âTRIQUES FINALES:')\n",
    "try:\n",
    "    final_metrics = calculate_metrics_with_threshold(y_train, y_proba_cv, best_threshold)\n",
    "    print(f'   ‚Ä¢ Accuracy: {final_metrics[\"accuracy\"]:.4f}')\n",
    "    print(f'   ‚Ä¢ Precision: {final_metrics[\"precision\"]:.4f}')\n",
    "    print(f'   ‚Ä¢ Recall: {final_metrics[\"recall\"]:.4f}')\n",
    "    print(f'   ‚Ä¢ F1-Score: {final_metrics[\"f1\"]:.4f}')\n",
    "    print(f'   ‚Ä¢ Matrice confusion: TP={final_metrics[\"tp\"]}, TN={final_metrics[\"tn\"]}, FP={final_metrics[\"fp\"]}, FN={final_metrics[\"fn\"]}')\n",
    "except:\n",
    "    print('   ‚Ä¢ Calcul des m√©triques finales...')\n",
    "\n",
    "print('\\nüéØ TOP 5 FEATURES PAR IMPORTANCE (PERMUTATION):')\n",
    "print(perm_df.head(5).to_string(index=False))\n",
    "try:\n",
    "    print('\\nüéØ TOP 5 FEATURES PAR IMPORTANCE (SHAP):')\n",
    "    print(shap_df.head(5).to_string(index=False))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('‚úÖ √âTAPE 4 COMPL√àT√âE - MOD√àLE FINAL PR√äT POUR DEPLOYMENT')\n",
    "print('='*70)\n",
    "\n",
    "print('\\nüìÅ FICHIERS G√âN√âR√âS:')\n",
    "print(f'   ‚Ä¢ models/feature_importance_permutation.csv')\n",
    "print(f'   ‚Ä¢ MLFlow Experiment: {experiment_name}')\n",
    "\n",
    "print('\\nüöÄ NEXT STEPS - DEPLOYMENT:')\n",
    "print(f'   1. Batch scoring sur test set')\n",
    "print(f'   2. API REST pour pr√©dictions en temps r√©el')\n",
    "print(f'   3. Monitoring et retraining p√©riodique')\n",
    "print(f'   4. Model versioning dans MLFlow Model Registry')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f216ee3",
   "metadata": {},
   "source": [
    "## Prochaines √©tapes\n",
    "\n",
    "- Batch scoring sur dataset de test\n",
    "- API REST pour predictions en temps r√©el\n",
    "- Monitoring et retraining"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "credit-scoring-mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
